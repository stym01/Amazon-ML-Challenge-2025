{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263fd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # ----------------------------\n",
    "# # 5. Combine Features (Text + Quantity)\n",
    "# # ----------------------------\n",
    "# X_train = hstack([X_text_train, train_df[['quantity']].values.astype(np.float64)])\n",
    "# X_test = hstack([X_text_test, test_df[['quantity']].values.astype(np.float64)])\n",
    "# y_train = train_df['price'].values\n",
    "\n",
    "# # ----------------------------\n",
    "# # 6. Log-transform target\n",
    "# # ----------------------------\n",
    "# y_train_log = np.log1p(y_train)\n",
    "\n",
    "# # ----------------------------\n",
    "# # 7. Train-validation split\n",
    "# # ----------------------------\n",
    "# X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "# lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n",
    "\n",
    "# params = {\n",
    "#     'objective': 'regression',\n",
    "#     'metric': 'mae',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'num_leaves': 64,\n",
    "#     'max_depth': 10,\n",
    "#     'feature_fraction': 0.8,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 5,\n",
    "#     'seed': 42\n",
    "# }\n",
    "\n",
    "# model = lgb.train(\n",
    "#     params,\n",
    "#     lgb_train,\n",
    "#     num_boost_round=1000,\n",
    "#     valid_sets=[lgb_train, lgb_val],\n",
    "#     early_stopping_rounds=50,\n",
    "#     verbose_eval=50\n",
    "# )\n",
    "\n",
    "# # ----------------------------\n",
    "# # 8. Validation Metrics\n",
    "# # ----------------------------\n",
    "# val_preds_log = model.predict(X_val)\n",
    "# val_preds = np.expm1(val_preds_log)\n",
    "# y_val_orig = np.expm1(y_val)\n",
    "\n",
    "# # Clip to avoid overflow\n",
    "# val_preds = np.clip(val_preds, 0, 1e6)\n",
    "# y_val_orig = np.clip(y_val_orig, 0, 1e6)\n",
    "\n",
    "# # MAE\n",
    "# val_mae = mean_absolute_error(y_val_orig, val_preds)\n",
    "# print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "# # SMAPE\n",
    "# def smape(y_true, y_pred):\n",
    "#     return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# val_smape = smape(y_val_orig, val_preds)\n",
    "# print(f\"Validation SMAPE: {val_smape:.4f}%\")\n",
    "\n",
    "# # ----------------------------\n",
    "# # 9. Predict on Test Set\n",
    "# # ----------------------------\n",
    "# preds_log = model.predict(X_test)\n",
    "# preds = np.expm1(preds_log)\n",
    "# preds = np.clip(preds, 0.01, 1e6)  # ensure positive and prevent overflow\n",
    "\n",
    "# # ----------------------------\n",
    "# # 10. Create Submission CSV\n",
    "# # ----------------------------\n",
    "# submission = pd.DataFrame({\n",
    "#     'sample_id': test_df['sample_id'],\n",
    "#     'price': np.round(preds, 2)\n",
    "# })\n",
    "\n",
    "# submission.to_csv('test_out2.csv', index=False)\n",
    "# print(\"✅ test_out2.csv generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46053a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01064768",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409544f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quantity(text):\n",
    "    value_match = re.search(r\"Value:\\s*([\\d.]+)\", str(text))\n",
    "    value = float(value_match.group(1)) if value_match else 1.0\n",
    "    \n",
    "    pack_match = re.search(r\"pack of (\\d+)\", str(text).lower())\n",
    "    pack = int(pack_match.group(1)) if pack_match else 1\n",
    "    \n",
    "    return value * pack\n",
    "\n",
    "train_df['quantity'] = train_df['catalog_content'].apply(extract_quantity).fillna(1)\n",
    "test_df['quantity'] = test_df['catalog_content'].apply(extract_quantity).fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a4fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).replace('\\n',' ').lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "train_df['clean_text'] = train_df['catalog_content'].apply(clean_text).fillna(\"unknown\")\n",
    "test_df['clean_text'] = test_df['catalog_content'].apply(clean_text).fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e736e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_text_train = vectorizer.fit_transform(train_df['clean_text'])\n",
    "X_text_test = vectorizer.transform(test_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a2a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_text_train, train_df[['quantity']].values.astype(np.float64)])\n",
    "X_test = hstack([X_text_test, test_df[['quantity']].values.astype(np.float64)])\n",
    "y_train = train_df['price'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af47092",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7358009-6553-40a4-9d52-7eb15fd01e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd27db0-8780-44e6-93f8-33a147ad59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_arr=X_train.toarray()\n",
    "# X_train_df=pd.DataFrame(X_train_arr)\n",
    "# X_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba68df5d-22ff-4952-8037-f6c7b92ce5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_df.to_csv('X_train_embeddings_train_tfidf_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce1bb67-b0ca-4777-a4c2-86e81af1c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_arr=X_test.toarray()\n",
    "# X_test_df=pd.DataFrame(X_test_arr)\n",
    "# X_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e723c3-4fe3-4264-8c6f-7a5a9a67a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_df.to_csv('X_test_embeddings_train_tfidf_words.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13676ed0-a357-4256-af45-5409e8999b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train_log, test_size=0.2, random_state=42)\n",
    "# # X_train_df['sample_id']= train_df['sample_id']\n",
    "\n",
    "# X_train_df.insert(0, 'sample_id', train_df['sample_id'])\n",
    "# X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e420cd9-293d-4f4b-a249-3131e82d23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_df['price']= train_df['price']\n",
    "# X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62ea9b81-401c-48f8-892b-13b189694057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_df.to_csv('X_train_embeddings_train_tfidf_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd7792-29cb-42a8-8022-cae69896ad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "858a03d5-32d5-4111-b02f-b1cdadd37cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_df.insert(0, 'sample_id', test_df['sample_id'])\n",
    "# X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc8d069-6f25-45d7-8793-5c4a5da43bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_df.to_csv('X_test_embeddings_train_tfidf_words.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8feafd1-8912-4439-a380-d1e06e86adb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3cb7e-f1fe-4de7-90d9-1bb1ee30335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e8492b6-8802-4d09-9708-af12c425b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =========================================================\n",
    "# # LightGBM Regressor with SMAPE\n",
    "# # =========================================================\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import lightgbm as lgb\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # =========================================================\n",
    "# # SMAPE metric\n",
    "# # =========================================================\n",
    "# def smape(y_true, y_pred):\n",
    "#     y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "#     denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "#     diff = np.abs(y_true - y_pred) / denominator\n",
    "#     diff[denominator == 0] = 0\n",
    "#     return np.mean(diff) * 100\n",
    "\n",
    "# # =========================================================\n",
    "# # Load Data\n",
    "# # =========================================================\n",
    "# data = pd.read_csv(\"/content/merged_correct_dataset.csv\")\n",
    "# X = data.drop(columns=[\"price\", \"image_link\", \"sample_id\"])\n",
    "# y = data[\"price\"].values\n",
    "\n",
    "# # =========================================================\n",
    "# # Train / Validation Split\n",
    "# # =========================================================\n",
    "# X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "# )\n",
    "\n",
    "# # =========================================================\n",
    "# # Scale features\n",
    "# # =========================================================\n",
    "# scaler = RobustScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "# X_val_scaled = scaler.transform(X_val_raw)\n",
    "\n",
    "# # =========================================================\n",
    "# # Log-transform target\n",
    "# # =========================================================\n",
    "# y_train_log = np.log1p(y_train)\n",
    "# y_val_log = np.log1p(y_val)\n",
    "\n",
    "# # =========================================================\n",
    "# # LightGBM model (scikit-learn API)\n",
    "# # =========================================================\n",
    "# lgb_model = lgb.LGBMRegressor(\n",
    "#     objective=\"regression\",\n",
    "#     learning_rate=0.05,\n",
    "#     n_estimators=250,\n",
    "#     num_leaves=32,\n",
    "#     feature_fraction=0.8,\n",
    "#     bagging_fraction=0.8,\n",
    "#     bagging_freq=1,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # =========================================================\n",
    "# # Fit with early stopping\n",
    "# # =========================================================\n",
    "# print(\"Training LightGBM...\")\n",
    "# lgb_model.fit(\n",
    "#     X_train_scaled, y_train_log,\n",
    "#     eval_set=[(X_val_scaled, y_val_log)],\n",
    "#     eval_metric=\"l2\",\n",
    "# )\n",
    "\n",
    "# # =========================================================\n",
    "# # Predict and evaluate\n",
    "# # =========================================================\n",
    "# y_pred_log = lgb_model.predict(X_val_scaled)\n",
    "# y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# mae = mean_absolute_error(y_val, y_pred)\n",
    "# smape_val = smape(y_val, y_pred)\n",
    "\n",
    "# print(\"==========================\")\n",
    "# print(f\"Final MAE: {mae:.4f}\")\n",
    "# print(f\"Final SMAPE: {smape_val:.2f}%\")\n",
    "# print(\"==========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb884e-49c8-4f64-bda7-6affadfbfb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059dd317-315e-4e24-9947-e94553dab995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736380a-d18f-496c-9df2-06600c58bb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560c55f-94bf-4c08-a94b-e791de02fb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6c6fa-c6cd-4036-946e-d9951cddf775",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_full = lgb.Dataset(X_train, label=y_train_log)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 64,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "# train on full data (no early stopping because no separate val set)\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_full,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.log_evaluation(period=50)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d58e2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l1: 0.607029\tval's l1: 0.627081\n",
      "[100]\ttrain's l1: 0.563022\tval's l1: 0.591703\n",
      "[150]\ttrain's l1: 0.542059\tval's l1: 0.577201\n",
      "[200]\ttrain's l1: 0.527177\tval's l1: 0.568141\n",
      "[250]\ttrain's l1: 0.515783\tval's l1: 0.561689\n",
      "[300]\ttrain's l1: 0.506548\tval's l1: 0.556942\n",
      "[350]\ttrain's l1: 0.498453\tval's l1: 0.55328\n",
      "[400]\ttrain's l1: 0.491778\tval's l1: 0.55041\n",
      "[450]\ttrain's l1: 0.485233\tval's l1: 0.54763\n",
      "[500]\ttrain's l1: 0.478729\tval's l1: 0.545354\n",
      "[550]\ttrain's l1: 0.473399\tval's l1: 0.543576\n",
      "[600]\ttrain's l1: 0.468024\tval's l1: 0.541622\n",
      "[650]\ttrain's l1: 0.463595\tval's l1: 0.539885\n",
      "[700]\ttrain's l1: 0.459156\tval's l1: 0.538501\n",
      "[750]\ttrain's l1: 0.454909\tval's l1: 0.537144\n",
      "[800]\ttrain's l1: 0.451079\tval's l1: 0.536337\n",
      "[850]\ttrain's l1: 0.447357\tval's l1: 0.535301\n",
      "[900]\ttrain's l1: 0.444165\tval's l1: 0.534448\n",
      "[950]\ttrain's l1: 0.44115\tval's l1: 0.533807\n",
      "[1000]\ttrain's l1: 0.43789\tval's l1: 0.53294\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's l1: 0.43789\tval's l1: 0.53294\n"
     ]
    }
   ],
   "source": [
    "# 7. Train-validation split\n",
    "# ----------------------------\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train_log, test_size=0.2, random_state=42)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 64,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     \"objective\": \"regression\",\n",
    "#     \"metric\": \"mae\",\n",
    "#     \"boosting_type\": \"gbdt\",\n",
    "#     \"learning_rate\": 0.01,        # slower learning for stability\n",
    "#     \"num_leaves\": 64,             # controls complexity (tradeoff with max_depth)\n",
    "#     \"max_depth\": 10,              # -1 for unlimited; 10 is safe\n",
    "#     \"min_data_in_leaf\": 30,       # prevents overfitting on small leaves\n",
    "#     \"min_sum_hessian_in_leaf\": 1e-3,\n",
    "#     \"feature_fraction\": 0.7,      # column subsampling\n",
    "#     \"bagging_fraction\": 0.7,      # row subsampling\n",
    "#     \"bagging_freq\": 5,\n",
    "#     \"lambda_l1\": 0.5,             # L1 regularization\n",
    "#     \"lambda_l2\": 0.5,             # L2 regularization\n",
    "#     \"min_gain_to_split\": 0.0,\n",
    "#     \"verbosity\": -1,\n",
    "#     \"seed\": 42\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    valid_names=['train', 'val'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=50)]\n",
    ")\n",
    "# .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7039b6-414d-4289-94df-f2acf8da50ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e6869-2f4b-439e-9f37-2e51166819b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_log = model.predict(X_val)\n",
    "val_preds = np.expm1(val_preds_log)\n",
    "y_val_orig = np.expm1(y_val)\n",
    "\n",
    "# Clip to avoid overflow\n",
    "val_preds = np.clip(val_preds, 0, 1e6)\n",
    "y_val_orig = np.clip(y_val_orig, 0, 1e6)\n",
    "\n",
    "# MAE\n",
    "val_mae = mean_absolute_error(y_val_orig, val_preds)\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "# SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "val_smape = smape(y_val_orig, val_preds)\n",
    "print(f\"Validation SMAPE: {val_smape:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_log = model.predict(X_test)\n",
    "preds = np.expm1(preds_log)\n",
    "preds = np.clip(preds, 0.01, 1e6)  # ensure positive and prevent overflow\n",
    "\n",
    "# ----------------------------\n",
    "# 10. Create Submission CSV\n",
    "# ----------------------------\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': test_df['sample_id'],\n",
    "    'price': np.round(preds, 2)\n",
    "})\n",
    "\n",
    "submission.to_csv('test_out5.csv', index=False)\n",
    "print(\"✅ test_out2.csv generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7665cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d142b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec2a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa96ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38b87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0338b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be107302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32af513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c7c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056404e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
